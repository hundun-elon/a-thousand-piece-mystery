{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Segmentation Model Training Using DeepLabv3 with ResNet 50 as backbone, wights are initinialized with those from imagenet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1. Imports and setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. CONFIGURATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CONFIGURATION\n",
            "======================================================================\n",
            "Model: deeplabv3plus with resnet50 backbone\n",
            "Image size: (512, 512)\n",
            "Batch size: 8\n",
            "Epochs: 50\n",
            "Learning rate: 0.0001\n"
          ]
        }
      ],
      "source": [
        "class Config:\n",
        "    \"\"\"Training configuration\"\"\"\n",
        "    # Model\n",
        "    MODEL_NAME = \"deeplabv3plus\"\n",
        "    BACKBONE = \"resnet50\"\n",
        "    IN_CHANNELS = 3\n",
        "    NUM_CLASSES = 1  # Binary segmentation (piece vs background)\n",
        "    \n",
        "    # Data\n",
        "    IMG_SIZE = (512, 512)  # Resize images to this size\n",
        "    BATCH_SIZE = 8\n",
        "    NUM_WORKERS = 4\n",
        "    \n",
        "    # Training\n",
        "    EPOCHS = 50\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "    \n",
        "    # Paths (relative to notebooks directory)\n",
        "    TRAIN_IMG_DIR = \"../data/train/images\"\n",
        "    TRAIN_MASK_DIR = \"../data/train/masks\"\n",
        "    VAL_IMG_DIR = \"../data/val/images\"\n",
        "    VAL_MASK_DIR = \"../data/val/masks\"\n",
        "    TEST_IMG_DIR = \"../data/test/images\"\n",
        "    TEST_MASK_DIR = \"../data/test/masks\"\n",
        "    \n",
        "    # Output paths\n",
        "    MODEL_DIR = \"../models/weights\"\n",
        "    OUTPUT_DIR = \"../output/experiments\"\n",
        "    \n",
        "    # Create directories\n",
        "    Path(MODEL_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Model: {config.MODEL_NAME} with {config.BACKBONE} backbone\")\n",
        "print(f\"Image size: {config.IMG_SIZE}\")\n",
        "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
        "print(f\"Epochs: {config.EPOCHS}\")\n",
        "print(f\"Learning rate: {config.LEARNING_RATE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. DATASET CLASS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PuzzleDataset(Dataset):\n",
        "    \"\"\"Dataset for puzzle piece segmentation\"\"\"\n",
        "    \n",
        "    def __init__(self, img_dir, mask_dir, transform=None):\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.mask_dir = Path(mask_dir)\n",
        "        self.transform = transform\n",
        "        \n",
        "        # Get all image files\n",
        "        self.image_files = sorted(list(self.img_dir.glob(\"*.jpg\")))\n",
        "        \n",
        "        print(f\"Found {len(self.image_files)} images in {img_dir}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_path = self.image_files[idx]\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        \n",
        "        # Load mask\n",
        "        mask_name = img_path.stem + \"_mask.png\"\n",
        "        mask_path = self.mask_dir / mask_name\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "        \n",
        "        # Normalize mask to 0 and 1\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "        \n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        \n",
        "        return image, mask.unsqueeze(0)  # Add channel dimension to mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. DATA AUGMENTATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_train_transform(img_size):\n",
        "    \"\"\"Training data augmentation\"\"\"\n",
        "    return A.Compose([\n",
        "        A.Resize(height=img_size[0], width=img_size[1]),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "        A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=3, p=1.0),\n",
        "            A.MedianBlur(blur_limit=3, p=1.0),\n",
        "        ], p=0.3),\n",
        "        A.OneOf([\n",
        "            A.RandomBrightnessContrast(p=1.0),\n",
        "            A.HueSaturationValue(p=1.0),\n",
        "        ], p=0.3),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_val_transform(img_size):\n",
        "    \"\"\"Validation data augmentation (no augmentation, just normalization)\"\"\"\n",
        "    return A.Compose([\n",
        "        A.Resize(height=img_size[0], width=img_size[1]),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. CREATE DATALOADERS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CREATING DATALOADERS\n",
            "======================================================================\n",
            "Found 350 images in ../data/train/images\n",
            "Found 75 images in ../data/val/images\n",
            "Found 75 images in ../data/test/images\n",
            "\n",
            "✓ Training batches: 44\n",
            "✓ Validation batches: 10\n",
            "✓ Test batches: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sphamandla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING DATALOADERS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PuzzleDataset(\n",
        "    config.TRAIN_IMG_DIR,\n",
        "    config.TRAIN_MASK_DIR,\n",
        "    transform=get_train_transform(config.IMG_SIZE)\n",
        ")\n",
        "\n",
        "val_dataset = PuzzleDataset(\n",
        "    config.VAL_IMG_DIR,\n",
        "    config.VAL_MASK_DIR,\n",
        "    transform=get_val_transform(config.IMG_SIZE)\n",
        ")\n",
        "\n",
        "test_dataset = PuzzleDataset(\n",
        "    config.TEST_IMG_DIR,\n",
        "    config.TEST_MASK_DIR,\n",
        "    transform=get_val_transform(config.IMG_SIZE)\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Training batches: {len(train_loader)}\")\n",
        "print(f\"✓ Validation batches: {len(val_loader)}\")\n",
        "print(f\"✓ Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. MODEL INITIALIZATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "INITIALIZING MODEL\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b5ab908d1e44f1d9e759974ab47739f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13b8054c4567426f8b5e0a452363a468",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model created: DeepLabV3+ with resnet50 backbone\n",
            "Encoder initialized with ImageNet weights\n",
            " Total parameters: 26,677,585\n",
            " Trainable parameters: 26,677,585\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create model\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=config.BACKBONE,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=config.IN_CHANNELS,\n",
        "    classes=config.NUM_CLASSES\n",
        ").to(device)\n",
        "\n",
        "print(f\" Model created: DeepLabV3+ with {config.BACKBONE} backbone\")\n",
        "print(f\"Encoder initialized with ImageNet weights\")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\" Total parameters: {total_params:,}\")\n",
        "print(f\" Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. LOSS FUNCTION AND METRICS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Loss function: Combined BCE + Dice Loss\n"
          ]
        }
      ],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss for binary segmentation\"\"\"\n",
        "    \n",
        "    def __init__(self, smooth=1.0):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.sigmoid(pred)\n",
        "        pred = pred.view(-1)\n",
        "        target = target.view(-1)\n",
        "        \n",
        "        intersection = (pred * target).sum()\n",
        "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
        "        \n",
        "        return 1 - dice\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    \"\"\"Combined BCE and Dice Loss\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        return self.bce(pred, target) + self.dice(pred, target)\n",
        "\n",
        "def calculate_iou(pred, target, threshold=0.5):\n",
        "    \"\"\"Calculate Intersection over Union (IoU)\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    target = target.float()\n",
        "    \n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum() - intersection\n",
        "    \n",
        "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "    return iou.item()\n",
        "\n",
        "# Initialize loss\n",
        "criterion = CombinedLoss()\n",
        "print(\"\\nLoss function: Combined BCE + Dice Loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. OPTIMIZER AND SCHEDULER\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Optimizer: AdamW\n",
            "✓ Scheduler: ReduceLROnPlateau (monitors validation IoU)\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config.LEARNING_RATE,\n",
        "    weight_decay=config.WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=5\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Optimizer: AdamW\")\n",
        "print(\"Scheduler: ReduceLROnPlateau (monitors validation IoU)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9. TRAINING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    \n",
        "    pbar = tqdm(loader, desc=\"Training\")\n",
        "    for images, masks in pbar:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Calculate metrics\n",
        "        iou = calculate_iou(outputs, masks)\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        running_iou += iou\n",
        "        \n",
        "        pbar.set_postfix({'loss': loss.item(), 'iou': iou})\n",
        "    \n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_iou = running_iou / len(loader)\n",
        "    \n",
        "    return epoch_loss, epoch_iou\n",
        "\n",
        "def validate_epoch(model, loader, criterion, device):\n",
        "    \"\"\"Validate for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(loader, desc=\"Validation\")\n",
        "        for images, masks in pbar:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            \n",
        "            # Calculate metrics\n",
        "            iou = calculate_iou(outputs, masks)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            running_iou += iou\n",
        "            \n",
        "            pbar.set_postfix({'loss': loss.item(), 'iou': iou})\n",
        "    \n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_iou = running_iou / len(loader)\n",
        "    \n",
        "    return epoch_loss, epoch_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 10. TRAINING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING TRAINING\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/44 [00:00<?, ?it/s]c:\\Users\\Sphamandla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Training history\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_iou': [],\n",
        "    'val_loss': [],\n",
        "    'val_iou': [],\n",
        "    'lr': []\n",
        "}\n",
        "\n",
        "best_val_iou = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 10\n",
        "\n",
        "for epoch in range(config.EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_iou = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_iou = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step(val_iou)\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_iou'].append(train_iou)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_iou'].append(val_iou)\n",
        "    history['lr'].append(current_lr)\n",
        "    \n",
        "    # Print metrics\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train IoU: {train_iou:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val IoU: {val_iou:.4f}\")\n",
        "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_iou > best_val_iou:\n",
        "        best_val_iou = val_iou\n",
        "        patience_counter = 0\n",
        "        \n",
        "        model_save_path = Path(config.MODEL_DIR) / f\"deeplabv3plus_resnet50_best.pth\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_iou': val_iou,\n",
        "            'config': config.__dict__\n",
        "        }, model_save_path)\n",
        "        \n",
        "        print(f\"✓ Best model saved! Val IoU: {val_iou:.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best Validation IoU: {best_val_iou:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 11. PLOT TRAINING HISTORY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PLOTTING TRAINING HISTORY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training and Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# IoU\n",
        "axes[1].plot(history['train_iou'], label='Train IoU', linewidth=2)\n",
        "axes[1].plot(history['val_iou'], label='Val IoU', linewidth=2)\n",
        "axes[1].axhline(y=best_val_iou, color='r', linestyle='--', label=f'Best Val IoU: {best_val_iou:.4f}')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('IoU')\n",
        "axes[1].set_title('Training and Validation IoU')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning Rate\n",
        "axes[2].plot(history['lr'], linewidth=2, color='green')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Learning Rate')\n",
        "axes[2].set_title('Learning Rate Schedule')\n",
        "axes[2].set_yscale('log')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{config.OUTPUT_DIR}/deeplabv3plus_resnet50_training_history.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Training history plots saved\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 12. EVALUATE ON TEST SET\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load best model\n",
        "checkpoint = torch.load(Path(config.MODEL_DIR) / \"deeplabv3plus_resnet50_best.pth\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(\"✓ Loaded best model weights\")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_iou = validate_epoch(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"  Loss: {test_loss:.4f}\")\n",
        "print(f\"  IoU: {test_iou:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 13. VISUALIZE PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VISUALIZING PREDICTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "model.eval()\n",
        "n_samples = 6\n",
        "\n",
        "# Get random samples from test set\n",
        "test_indices = np.random.choice(len(test_dataset), n_samples, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(n_samples, 3, figsize=(12, 3*n_samples))\n",
        "fig.suptitle('Test Set Predictions: Image | Ground Truth | Prediction', fontsize=16, y=1.00)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, test_idx in enumerate(test_indices):\n",
        "        # Get sample\n",
        "        image, mask = test_dataset[test_idx]\n",
        "        \n",
        "        # Predict\n",
        "        image_input = image.unsqueeze(0).to(device)\n",
        "        output = model(image_input)\n",
        "        pred_mask = torch.sigmoid(output).cpu().numpy()[0, 0]\n",
        "        \n",
        "        # Denormalize image for visualization\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img_viz = image.permute(1, 2, 0).numpy()\n",
        "        img_viz = (img_viz * std + mean).clip(0, 1)\n",
        "        \n",
        "        # Plot\n",
        "        axes[idx, 0].imshow(img_viz)\n",
        "        axes[idx, 0].set_title('Input Image')\n",
        "        axes[idx, 0].axis('off')\n",
        "        \n",
        "        axes[idx, 1].imshow(mask[0], cmap='gray')\n",
        "        axes[idx, 1].set_title('Ground Truth')\n",
        "        axes[idx, 1].axis('off')\n",
        "        \n",
        "        axes[idx, 2].imshow(pred_mask, cmap='gray')\n",
        "        axes[idx, 2].set_title(f'Prediction')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{config.OUTPUT_DIR}/deeplabv3plus_resnet50_predictions.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Prediction visualizations saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 14. SAVE FINAL RESULTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = {\n",
        "    'model': config.MODEL_NAME,\n",
        "    'backbone': config.BACKBONE,\n",
        "    'image_size': config.IMG_SIZE,\n",
        "    'batch_size': config.BATCH_SIZE,\n",
        "    'epochs_trained': len(history['train_loss']),\n",
        "    'best_val_iou': float(best_val_iou),\n",
        "    'test_iou': float(test_iou),\n",
        "    'test_loss': float(test_loss),\n",
        "    'final_lr': float(history['lr'][-1]),\n",
        "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    'history': {k: [float(v) for v in vals] for k, vals in history.items()}\n",
        "}\n",
        "\n",
        "results_path = Path(config.OUTPUT_DIR) / \"deeplabv3plus_resnet50_results.json\"\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"✓ Results saved to {results_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPERIMENT COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  Best Validation IoU: {best_val_iou:.4f}\")\n",
        "print(f\"  Test IoU: {test_iou:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
