# COMS4036A Computer Vision - 1000-Piece Puzzle Project

## Project Overview
This project implements an end-to-end computer vision pipeline to solve a 1000-piece puzzle using segmentation, feature matching, and geometric assembly techniques.

## Team Members
- [Member 1 Name] - [Student Number]
- [Member 2 Name] - [Student Number]
- [Member 3 Name] - [Student Number]

## Project Structure

```
.
â”œâ”€â”€ data/                      # Data directory (not in git)
â”‚   â”œâ”€â”€ images/               # All 1000 puzzle piece images
â”‚   â”œâ”€â”€ masks/                # 500 training masks + 500 predicted
â”‚   â”œâ”€â”€ train/                # Training data subset
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ masks/
â”‚   â””â”€â”€ test/                 # Test data subset
â”‚       â””â”€â”€ images/
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ segmentation/         # Segmentation module
â”‚   â”‚   â”œâ”€â”€ model.py         # Model architecture
â”‚   â”‚   â”œâ”€â”€ train.py         # Training script
â”‚   â”‚   â””â”€â”€ predict.py       # Inference script
â”‚   â”œâ”€â”€ matching/             # Feature matching module
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â””â”€â”€ graph_builder.py
â”‚   â”œâ”€â”€ assembly/             # Puzzle assembly module
â”‚   â”‚   â””â”€â”€ assembler.py
â”‚   â”œâ”€â”€ utils/                # Utility functions
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â””â”€â”€ config.py             # Configuration settings
â”‚
â”œâ”€â”€ models/                    # Model definitions and weights
â”‚   â”œâ”€â”€ segmentation/
â”‚   â”œâ”€â”€ matching/
â”‚   â””â”€â”€ weights/              # Trained model weights
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for experiments
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_segmentation_training.ipynb
â”‚   â”œâ”€â”€ 03_feature_extraction.ipynb
â”‚   â”œâ”€â”€ 04_graph_construction.ipynb
â”‚   â”œâ”€â”€ 05_puzzle_assembly.ipynb
â”‚   â””â”€â”€ 06_evaluation.ipynb
â”‚
â”œâ”€â”€ output/                    # Output directory
â”‚   â”œâ”€â”€ masks/                # Predicted masks
â”‚   â”œâ”€â”€ visualizations/       # Plots and figures
â”‚   â””â”€â”€ experiments/          # Experiment results
â”‚
â”œâ”€â”€ report/                    # Report files
â”‚   â”œâ”€â”€ figures/              # Report figures
â”‚   â””â”€â”€ latex/                # LaTeX source files
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ run.sh                     # Main execution script
â”œâ”€â”€ setup.py                   # Project setup script
â”œâ”€â”€ graph.json                 # Output: adjacency graph
â”œâ”€â”€ final.png                  # Output: assembled puzzle
â””â”€â”€ README.md                  # This file
```

## Setup Instructions

### 1. Clone and Setup
```bash
# Run the setup script to create project structure
python setup.py

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Data Organization
Place the provided data in the following structure:
```
data/
  images/          # All 1000 images
  masks/           # 500 labeled masks
```

The training scripts will automatically split data into train/test sets.

## Pipeline Components

### 1. Segmentation (25%)
**Goal:** Extract puzzle pieces from images

**Approach:**
- Model: [U-Net / Mask R-CNN / DeepLabV3 / Custom]
- Input: RGB images of puzzle pieces
- Output: Binary masks (0=background, 1=piece)
- Metric: Mean IoU

**Files:**
- `src/segmentation/model.py`: Model architecture
- `src/segmentation/train.py`: Training pipeline
- `src/segmentation/predict.py`: Inference on test set

### 2. Graph Construction (25%)
**Goal:** Determine which pieces are adjacent

**Approach:**
- Extract edge features (shape + texture)
- Compute similarity between piece edges
- Build adjacency graph with neighbors
- Metric: Precision & Recall of edges

**Files:**
- `src/matching/feature_extraction.py`: Feature extraction
- `src/matching/graph_builder.py`: Graph construction

### 3. Puzzle Assembly (15%)
**Goal:** Reconstruct the complete puzzle

**Approach:**
- Use adjacency graph to position pieces
- Apply affine/projective transformations
- Assemble pieces on canvas
- Metric: Visual quality and connected regions

**Files:**
- `src/assembly/assembler.py`: Assembly algorithm

## Running the Project

### Training Phase
```bash
# Train segmentation model
python -m src.segmentation.train

# Extract features and build initial graph
python -m src.matching.feature_extraction
```

### Inference Phase (Submission)
```bash
# Run complete pipeline
./run.sh

# This generates:
# - ./data/masks/*.png (500 predicted masks)
# - ./graph.json (adjacency graph)
# - ./final.png (assembled puzzle)
```

## Deliverables

### 1. Segmentation Masks (Moodle)
- ZIP file containing 500 predicted masks
- Format: `IMG_XXXXXXX_mask.png` (binary PNG, values 0 or 1)

### 2. Adjacency Graph (Moodle)
- JSON file: `graph.json`
- Format: `{"piece_id": ["neighbor1", "neighbor2", ...]}`

### 3. Final Submission Package (Moodle)
```
submission.zip
  â”œâ”€â”€ src/                    # All source code
  â”œâ”€â”€ models/weights/         # Trained model weights
  â”œâ”€â”€ notebooks/              # Jupyter notebooks
  â”œâ”€â”€ requirements.txt        # Dependencies
  â”œâ”€â”€ run.sh                  # Inference script
  â”œâ”€â”€ report.pdf              # IEEE format report (4-6 pages)
  â””â”€â”€ README.md               # This file
```

**Note:** Do NOT include data/images or data/masks in submission.

## Report Structure (35%)

IEEE two-column format, 4-6 pages:

1. **Pipeline Overview**
   - High-level architecture
   - Design rationale

2. **Methods**
   - Segmentation approach
   - Feature extraction and matching
   - Assembly algorithm

3. **Metrics & Results**
   - Segmentation: IoU scores
   - Graph: Precision, Recall, F1
   - Assembly: Visual quality metrics

4. **Reflection**
   - What worked and why
   - What failed and why
   - Limitations and future work

5. **Final Reconstruction**
   - Full-page assembled puzzle (last page, landscape)

## Mark Allocation

| Component                | Weight |
|--------------------------|--------|
| Segmentation Performance | 25%    |
| Graph Connectivity       | 25%    |
| Final Image Quality      | 15%    |
| Report                   | 35%    |
| **Total**                | **100%** |

## Development Workflow

### Branch Strategy (Suggested)
- `main`: Stable code only
- `dev`: Integration branch
- `feature/segmentation`: Segmentation work
- `feature/matching`: Matching work
- `feature/assembly`: Assembly work

### Commit Guidelines
- Use clear, descriptive commit messages
- Commit working code frequently
- Don't commit large data files

## Useful Resources

- [OpenCV Documentation](https://docs.opencv.org/)
- [PyTorch Segmentation Models](https://github.com/qubvel/segmentation_models.pytorch)
- [NetworkX Documentation](https://networkx.org/documentation/stable/)
- IEEE Paper Template: [Overleaf](https://www.overleaf.com/latex/templates/ieee-conference-template/grfzhhncsfqn)

## Tips and Best Practices

1. **Start Simple**: Get a basic pipeline working end-to-end first
2. **Iterate**: Improve each component incrementally
3. **Visualize**: Create visualizations at each stage
4. **Metrics**: Track metrics throughout development
5. **Document**: Keep notes on what you try and results
6. **Version Control**: Commit frequently with meaningful messages

## Troubleshooting

### Common Issues
- **Out of memory**: Reduce batch size or image resolution
- **Poor segmentation**: Try data augmentation or different model
- **Slow training**: Use GPU if available, reduce model size
- **Poor matching**: Augment features with color/texture information

## Due Date
**14:00 on 31 October 2025**

## Contact
For questions, contact Prof. Richard Klein or use the course forum.

---
*Good luck with the puzzle!* ðŸ§©
